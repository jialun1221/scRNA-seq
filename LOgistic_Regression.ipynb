{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jialun1221/scRNA-seq/blob/main/LOgistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQmvZLCHTD80"
      },
      "outputs": [],
      "source": [
        "!pip3 install scanpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import sys\n",
        "import random\n",
        "from sklearn import preprocessing \n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import importlib\n",
        "required_libraries = ['torch', 'torchvision', 'PIL', 'matplotlib', \n",
        "                      'numpy', 'pandas']\n",
        "for lib in required_libraries:\n",
        "    if importlib.util.find_spec(lib) is None:\n",
        "        print(\"%s unavailable\" % lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-NBAnqRb8Oa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h92O1LyqV1h0"
      },
      "outputs": [],
      "source": [
        "#0. Model methods import\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icWjnYVQT2zh"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# adata_m1 = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/PC_all_genes_corrected.h5ad\")\n",
        "# adata_m2 = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/pca_in_obsm_2500.h5ad\")\n",
        "# adata_m3 = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/2500no_pca_new.h5ad\")\n",
        "\n",
        "# data_list = [adata_m1, adata_m2, adata_m3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afmps_Kcb7W8",
        "outputId": "8cd9906e-1657-47bc-b0a5-222f4051b0e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "adata_m1 = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/MG_PC_all_genes.h5ad\")\n",
        "adata_m2 = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/MG_PC_HVGs.h5ad\")\n",
        "adata_m3 = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/MG_no_PC_HVGs.h5ad\")\n",
        "\n",
        "data_list = [adata_m1, adata_m2, adata_m3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adata_m1"
      ],
      "metadata": {
        "id": "8DW5alcJNCXW",
        "outputId": "5fb164b2-a92b-484c-b8b3-c5de9783c82d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AnnData object with n_obs × n_vars = 24082 × 29464\n",
              "    obs: 'level_0', 'index', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'Cell_Subtype', 'Cell_Type', 'disease__ontology_label', 'organ__ontology_label', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'\n",
              "    var: 'features', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
              "    uns: 'hvg', 'log1p', 'pca'\n",
              "    obsm: 'X_pca'\n",
              "    varm: 'PCs'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Pl-Ybokw44m"
      },
      "outputs": [],
      "source": [
        "df_astro_lr = pd.DataFrame(columns = ['Seed', 'aLR m1 val', 'aLR m2 val', 'aLR m3 val','aLR m1 test', 'aLR m2 test', 'aLR m3 test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADz_1DoBxLHj"
      },
      "outputs": [],
      "source": [
        "dict_list_astro_lr_m1 = []\n",
        "dict_list_astro_lr_m2 = []\n",
        "dict_list_astro_lr_m3 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewnab_K4WnQD"
      },
      "outputs": [],
      "source": [
        "#0. Define Logistic Regression Model \n",
        "def logisticRegressionTest():\n",
        "\n",
        "  use_gpu = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "  model = LogisticRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "  prediction_test = model.predict(X_test)\n",
        "\n",
        "  #test accruacy \n",
        "  accuracy_test = metrics.accuracy_score(y_test, prediction_test)\n",
        "  print(\"Test acc = \", metrics.accuracy_score(y_test, prediction_test))\n",
        "  \n",
        "  return prediction_test, accuracy_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rZwE39Iv3jk"
      },
      "outputs": [],
      "source": [
        "#0. Define Logistic Regression Model for Validation\n",
        "def logisticRegressionValidation():\n",
        "\n",
        "  use_gpu = torch.cuda.is_available()\n",
        "  device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "  model = LogisticRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "  prediction_test_val = model.predict(X_val)\n",
        "\n",
        "  #validation accuracy  \n",
        "  accuracy_val = metrics.accuracy_score(y_val, prediction_test_val)\n",
        "  print(\"Validation acc = \", metrics.accuracy_score(y_val, prediction_test_val))\n",
        "  \n",
        "  return prediction_test_val, accuracy_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1iS1UwubTSH"
      },
      "outputs": [],
      "source": [
        "def plot(y_test, prediction_test):\n",
        "  confusion_matrix = metrics.confusion_matrix(y_test, prediction_test)\n",
        "  # cmd = ConfusionMatrixDisplay(confusion_matrix, display_labels=['Healthy','PD'])\n",
        "  cmd = ConfusionMatrixDisplay(confusion_matrix, display_labels=['Healthy','PD'])\n",
        "  cmd.plot(cmap = 'YlGnBu', colorbar = False)\n",
        "\n",
        "  plt.grid(False)\n",
        "\n",
        "  fig = cmd.ax_.get_figure() \n",
        "  ax = fig.add_axes(['Healthy', 'PD'])\n",
        "\n",
        "  ax.set_xticklabels(['Healthy', 'PD'])\n",
        "  ax.set_ytickslabels(['Healthy', 'PD'])\n",
        "\n",
        "  fig.set_figwidth(3)\n",
        "  fig.set_figheight(3)\n",
        "  plt.rcParams[\"figure.dpi\"] = 300\n",
        "  plt.rcParams[\"axes.labelcolor\"] = 'black' #now useless\n",
        "\n",
        "  plt.rc('font', size=16)\n",
        "  # Set the axes title font size\n",
        "  plt.rc('axes', titlesize=14)\n",
        "  # Set the axes labels font size\n",
        "  plt.rc('axes', labelsize=14)\n",
        "  # Set the font size for x tick labels\n",
        "  plt.rc('xtick', labelsize=14)\n",
        "  # Set the font size for y tick labels\n",
        "  plt.rc('ytick', labelsize=14)\n",
        "  #plt.savefig(dpi = 300, fname = 'astro_LR.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LqoQyyIs4yG"
      },
      "source": [
        "mega-loop!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51oniGdSswU3",
        "outputId": "8d1d9cab-3277-4ea2-8212-f6c778145265"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "AnnData object with n_obs × n_vars = 24082 × 29464\n",
            "    obs: 'index', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'Cell_Subtype', 'Cell_Type', 'disease__ontology_label', 'organ__ontology_label', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'\n",
            "    var: 'features', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
            "    uns: 'hvg', 'log1p', 'pca'\n",
            "    obsm: 'X_pca'\n",
            "    varm: 'PCs'\n",
            "seed:  4951\n",
            "Validation acc =  0.9738426406477061\n",
            "Test acc =  0.9765414158189745\n",
            "seed:  2395\n",
            "Validation acc =  0.9736350425576085\n",
            "Test acc =  0.9757110234585842\n",
            "seed:  3749\n",
            "Validation acc =  0.978202200539755\n",
            "Test acc =  0.9761262196387793\n",
            "seed:  2986\n",
            "Validation acc =  0.9757110234585842\n",
            "Test acc =  0.9759186215486817\n",
            "seed:  9700\n",
            "Validation acc =  0.9763338177288768\n",
            "Test acc =  0.9765414158189745\n",
            "seed:  4657\n",
            "Validation acc =  0.9771642100892671\n",
            "Test acc =  0.9773718081793648\n",
            "seed:  7258\n",
            "Validation acc =  0.978202200539755\n",
            "Test acc =  0.9771642100892671\n",
            "seed:  2700\n",
            "Validation acc =  0.9794477890803405\n",
            "Test acc =  0.9759186215486817\n",
            "seed:  9275\n",
            "Validation acc =  0.9746730330080964\n",
            "Test acc =  0.9765414158189745\n",
            "seed:  3899\n",
            "Validation acc =  0.9748806310981939\n",
            "Test acc =  0.9765414158189745\n",
            "1\n",
            "AnnData object with n_obs × n_vars = 24082 × 2500\n",
            "    obs: 'index', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'Cell_Subtype', 'Cell_Type', 'disease__ontology_label', 'organ__ontology_label', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'\n",
            "    var: 'features', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
            "    uns: 'hvg', 'log1p', 'pca'\n",
            "    obsm: 'X_pca'\n",
            "    varm: 'PCs'\n",
            "seed =  3899\n",
            "4951\n",
            "Validation acc =  0.9634627361428275\n",
            "Test acc =  0.9597259705210712\n",
            "seed =  3899\n",
            "2395\n",
            "Validation acc =  0.9582727838903882\n",
            "Test acc =  0.9599335686111687\n",
            "seed =  3899\n",
            "3749\n",
            "Validation acc =  0.9647083246834129\n",
            "Test acc =  0.9588955781606809\n",
            "seed =  3899\n",
            "2986\n",
            "Validation acc =  0.9624247456923396\n",
            "Test acc =  0.9597259705210712\n",
            "seed =  3899\n",
            "9700\n",
            "Validation acc =  0.9622171476022421\n",
            "Test acc =  0.9597259705210712\n",
            "seed =  3899\n",
            "4657\n",
            "Validation acc =  0.9655387170438032\n",
            "Test acc =  0.9586879800705833\n",
            "seed =  3899\n",
            "7258\n",
            "Validation acc =  0.9613867552418518\n",
            "Test acc =  0.9605563628814615\n",
            "seed =  3899\n",
            "2700\n",
            "Validation acc =  0.963670334232925\n",
            "Test acc =  0.9591031762507785\n",
            "seed =  3899\n",
            "9275\n",
            "Validation acc =  0.9593107743408761\n",
            "Test acc =  0.9593107743408761\n",
            "seed =  3899\n",
            "3899\n",
            "Validation acc =  0.9593107743408761\n",
            "Test acc =  0.9588955781606809\n",
            "2\n",
            "AnnData object with n_obs × n_vars = 24082 × 2500\n",
            "    obs: 'index', 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'Cell_Subtype', 'Cell_Type', 'disease__ontology_label', 'organ__ontology_label', 'n_genes', 'n_genes_by_counts', 'total_counts', 'total_counts_mt', 'pct_counts_mt'\n",
            "    var: 'features', 'n_cells', 'mt', 'n_cells_by_counts', 'mean_counts', 'pct_dropout_by_counts', 'total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm', 'mean', 'std'\n",
            "    uns: 'hvg', 'log1p'\n",
            "seed =  3899\n",
            "4951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9543284201785344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9501764583765829\n",
            "seed =  3899\n",
            "2395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.957857587710193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9541208220884367\n",
            "seed =  3899\n",
            "3749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9580651858002907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9537056259082416\n",
            "seed =  3899\n",
            "2986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9530828316379489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9553664106290222\n",
            "seed =  3899\n",
            "9700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9547436163587295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9522524392775586\n",
            "seed =  3899\n",
            "4657\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9561968029894125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9561968029894125\n",
            "seed =  3899\n",
            "7258\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9572347934399004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9545360182686319\n",
            "seed =  3899\n",
            "2700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9553664106290222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9522524392775586\n",
            "seed =  3899\n",
            "9275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9566119991696076\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test acc =  0.9576499896200955\n",
            "seed =  3899\n",
            "3899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc =  0.9555740087191198\n",
            "Test acc =  0.9539132239983392\n",
            "[{'Seed': 4951, 'aLR m1 val': 0.9738426406477061, 'aLR m1 test': 0.9765414158189745}, {'Seed': 2395, 'aLR m1 val': 0.9736350425576085, 'aLR m1 test': 0.9757110234585842}, {'Seed': 3749, 'aLR m1 val': 0.978202200539755, 'aLR m1 test': 0.9761262196387793}, {'Seed': 2986, 'aLR m1 val': 0.9757110234585842, 'aLR m1 test': 0.9759186215486817}, {'Seed': 9700, 'aLR m1 val': 0.9763338177288768, 'aLR m1 test': 0.9765414158189745}, {'Seed': 4657, 'aLR m1 val': 0.9771642100892671, 'aLR m1 test': 0.9773718081793648}, {'Seed': 7258, 'aLR m1 val': 0.978202200539755, 'aLR m1 test': 0.9771642100892671}, {'Seed': 2700, 'aLR m1 val': 0.9794477890803405, 'aLR m1 test': 0.9759186215486817}, {'Seed': 9275, 'aLR m1 val': 0.9746730330080964, 'aLR m1 test': 0.9765414158189745}, {'Seed': 3899, 'aLR m1 val': 0.9748806310981939, 'aLR m1 test': 0.9765414158189745}]\n",
            "[{'Seed': 4951, 'aLR m2 val': 0.9634627361428275, 'aLR m2 test': 0.9597259705210712}, {'Seed': 2395, 'aLR m2 val': 0.9582727838903882, 'aLR m2 test': 0.9599335686111687}, {'Seed': 3749, 'aLR m2 val': 0.9647083246834129, 'aLR m2 test': 0.9588955781606809}, {'Seed': 2986, 'aLR m2 val': 0.9624247456923396, 'aLR m2 test': 0.9597259705210712}, {'Seed': 9700, 'aLR m2 val': 0.9622171476022421, 'aLR m2 test': 0.9597259705210712}, {'Seed': 4657, 'aLR m2 val': 0.9655387170438032, 'aLR m2 test': 0.9586879800705833}, {'Seed': 7258, 'aLR m2 val': 0.9613867552418518, 'aLR m2 test': 0.9605563628814615}, {'Seed': 2700, 'aLR m2 val': 0.963670334232925, 'aLR m2 test': 0.9591031762507785}, {'Seed': 9275, 'aLR m2 val': 0.9593107743408761, 'aLR m2 test': 0.9593107743408761}, {'Seed': 3899, 'aLR m2 val': 0.9593107743408761, 'aLR m2 test': 0.9588955781606809}]\n",
            "[{'Seed': 4951, 'aLR m3 val': 0.9543284201785344, 'aLR m3 test': 0.9501764583765829}, {'Seed': 2395, 'aLR m3 val': 0.957857587710193, 'aLR m3 test': 0.9541208220884367}, {'Seed': 3749, 'aLR m3 val': 0.9580651858002907, 'aLR m3 test': 0.9537056259082416}, {'Seed': 2986, 'aLR m3 val': 0.9530828316379489, 'aLR m3 test': 0.9553664106290222}, {'Seed': 9700, 'aLR m3 val': 0.9547436163587295, 'aLR m3 test': 0.9522524392775586}, {'Seed': 4657, 'aLR m3 val': 0.9561968029894125, 'aLR m3 test': 0.9561968029894125}, {'Seed': 7258, 'aLR m3 val': 0.9572347934399004, 'aLR m3 test': 0.9545360182686319}, {'Seed': 2700, 'aLR m3 val': 0.9553664106290222, 'aLR m3 test': 0.9522524392775586}, {'Seed': 9275, 'aLR m3 val': 0.9566119991696076, 'aLR m3 test': 0.9576499896200955}, {'Seed': 3899, 'aLR m3 val': 0.9555740087191198, 'aLR m3 test': 0.9539132239983392}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "i = 0 #method number\n",
        "\n",
        "seed_list = []\n",
        "\n",
        "for dataobj in data_list:\n",
        "  print(i)\n",
        "  print(dataobj)\n",
        "  i = i + 1\n",
        "  adata = dataobj\n",
        "\n",
        "  #1. Pre-process data\n",
        "  if 'level_0' not in adata.obs.columns:\n",
        "    adata.obs = adata.obs.reset_index() #reset the index for X, so the column number starts from 0\n",
        "\n",
        "  if 'X_pca' in adata.obsm:\n",
        "    #if i == 0:\n",
        "    # if isinstance(adata.obsm['X_pca'].X, np.ndarray):\n",
        "    X = adata.obsm['X_pca'].X\n",
        "    # elif isinstance(adata.obsm['X_pca'], np.ndarray):\n",
        "    #   X = adata.obsm['X_pca']\n",
        "    # else:\n",
        "    #   # X = pd.DataFrame(adata.obsm['X_pca']) #DataFrame constructor not properly called!\n",
        "    #   X = adata.obsm['X_pca']\n",
        "  else:\n",
        "    X = adata.X \n",
        "  \n",
        "  y = adata.obs['disease__ontology_label'].replace({\"normal\": \"0\", \"Parkinson disease\": \"1\"})\n",
        "\n",
        "  #2. Train-test split: 60/20/20. Random_state is the seed.Validation used for hyperparameter tuning. \n",
        "  #   Parameters for the highest accuracy can be used for test set.\n",
        "  \n",
        "  X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(X, y, test_size=0.2, random_state=0) #test is always the same\n",
        "\n",
        "  #3. run 10 iterations\n",
        "  for m in range (10):\n",
        "    X_test = copy.deepcopy(X_test_global)\n",
        "    y_test = copy.deepcopy(y_test_global)\n",
        "    \n",
        "    if len(seed_list) < 10:\n",
        "      seed = random.randint(0, 9999)\n",
        "      seed_list.append(seed)\n",
        "      print(\"seed: \", seed)\n",
        "      X_train, X_val, y_train, y_val = train_test_split(X_train_global, y_train_global, test_size=0.25, random_state= seed_list[m])\n",
        "    else:\n",
        "      print(\"seed = \", seed)\n",
        "      print(seed_list[m])\n",
        "      X_train, X_val, y_train, y_val = train_test_split(X_train_global, y_train_global, test_size=0.25, random_state= seed_list[m])\n",
        "\n",
        "    prediction_val, accuracy_val = logisticRegressionValidation()\n",
        "    prediction_test, accuracy_test = logisticRegressionTest()\n",
        "\n",
        "    if i == 1: #write in method 1 section\n",
        "      row_dict_m1 = {'Seed': seed_list[m], 'aLR m1 val': accuracy_val, 'aLR m1 test': accuracy_test}\n",
        "      dict_list_astro_lr_m1.append(row_dict_m1)\n",
        "    elif i == 2:\n",
        "      row_dict_m2 = {'Seed': seed_list[m], 'aLR m2 val': accuracy_val, 'aLR m2 test': accuracy_test}\n",
        "      dict_list_astro_lr_m2.append(row_dict_m2)\n",
        "    elif i == 3:\n",
        "      row_dict_m3 = {'Seed': seed_list[m], 'aLR m3 val': accuracy_val, 'aLR m3 test': accuracy_test}\n",
        "      dict_list_astro_lr_m3.append(row_dict_m3)\n",
        "      \n",
        "print(dict_list_astro_lr_m1)\n",
        "print(dict_list_astro_lr_m2)\n",
        "print(dict_list_astro_lr_m3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opdNdTt9Vpff"
      },
      "outputs": [],
      "source": [
        "df_astro_m1 = pd.DataFrame.from_dict(dict_list_astro_lr_m1)\n",
        "df_astro_m2 = pd.DataFrame.from_dict(dict_list_astro_lr_m2)\n",
        "df_astro_m3 = pd.DataFrame.from_dict(dict_list_astro_lr_m3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "Ue6h7lECXvQd",
        "outputId": "2be21083-d31c-4ec6-8d43-b7f3fe8276ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Seed  aLR m1 val  aLR m1 test  aLR m2 val  aLR m2 test  aLR m3 val  \\\n",
              "0  4951    0.973843     0.976541         NaN          NaN         NaN   \n",
              "1  2395    0.973635     0.975711         NaN          NaN         NaN   \n",
              "2  3749    0.978202     0.976126         NaN          NaN         NaN   \n",
              "3  2986    0.975711     0.975919         NaN          NaN         NaN   \n",
              "4  9700    0.976334     0.976541         NaN          NaN         NaN   \n",
              "5  4657    0.977164     0.977372         NaN          NaN         NaN   \n",
              "6  7258    0.978202     0.977164         NaN          NaN         NaN   \n",
              "7  2700    0.979448     0.975919         NaN          NaN         NaN   \n",
              "8  9275    0.974673     0.976541         NaN          NaN         NaN   \n",
              "9  3899    0.974881     0.976541         NaN          NaN         NaN   \n",
              "0  4951         NaN          NaN    0.963463     0.959726         NaN   \n",
              "1  2395         NaN          NaN    0.958273     0.959934         NaN   \n",
              "2  3749         NaN          NaN    0.964708     0.958896         NaN   \n",
              "3  2986         NaN          NaN    0.962425     0.959726         NaN   \n",
              "4  9700         NaN          NaN    0.962217     0.959726         NaN   \n",
              "5  4657         NaN          NaN    0.965539     0.958688         NaN   \n",
              "6  7258         NaN          NaN    0.961387     0.960556         NaN   \n",
              "7  2700         NaN          NaN    0.963670     0.959103         NaN   \n",
              "8  9275         NaN          NaN    0.959311     0.959311         NaN   \n",
              "9  3899         NaN          NaN    0.959311     0.958896         NaN   \n",
              "0  4951         NaN          NaN         NaN          NaN    0.954328   \n",
              "1  2395         NaN          NaN         NaN          NaN    0.957858   \n",
              "2  3749         NaN          NaN         NaN          NaN    0.958065   \n",
              "3  2986         NaN          NaN         NaN          NaN    0.953083   \n",
              "4  9700         NaN          NaN         NaN          NaN    0.954744   \n",
              "5  4657         NaN          NaN         NaN          NaN    0.956197   \n",
              "6  7258         NaN          NaN         NaN          NaN    0.957235   \n",
              "7  2700         NaN          NaN         NaN          NaN    0.955366   \n",
              "8  9275         NaN          NaN         NaN          NaN    0.956612   \n",
              "9  3899         NaN          NaN         NaN          NaN    0.955574   \n",
              "\n",
              "   aLR m3 test  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "2          NaN  \n",
              "3          NaN  \n",
              "4          NaN  \n",
              "5          NaN  \n",
              "6          NaN  \n",
              "7          NaN  \n",
              "8          NaN  \n",
              "9          NaN  \n",
              "0          NaN  \n",
              "1          NaN  \n",
              "2          NaN  \n",
              "3          NaN  \n",
              "4          NaN  \n",
              "5          NaN  \n",
              "6          NaN  \n",
              "7          NaN  \n",
              "8          NaN  \n",
              "9          NaN  \n",
              "0     0.950176  \n",
              "1     0.954121  \n",
              "2     0.953706  \n",
              "3     0.955366  \n",
              "4     0.952252  \n",
              "5     0.956197  \n",
              "6     0.954536  \n",
              "7     0.952252  \n",
              "8     0.957650  \n",
              "9     0.953913  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b485ceee-4332-4f37-9f24-c8a95ed67353\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Seed</th>\n",
              "      <th>aLR m1 val</th>\n",
              "      <th>aLR m1 test</th>\n",
              "      <th>aLR m2 val</th>\n",
              "      <th>aLR m2 test</th>\n",
              "      <th>aLR m3 val</th>\n",
              "      <th>aLR m3 test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4951</td>\n",
              "      <td>0.973843</td>\n",
              "      <td>0.976541</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2395</td>\n",
              "      <td>0.973635</td>\n",
              "      <td>0.975711</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3749</td>\n",
              "      <td>0.978202</td>\n",
              "      <td>0.976126</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2986</td>\n",
              "      <td>0.975711</td>\n",
              "      <td>0.975919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9700</td>\n",
              "      <td>0.976334</td>\n",
              "      <td>0.976541</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4657</td>\n",
              "      <td>0.977164</td>\n",
              "      <td>0.977372</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7258</td>\n",
              "      <td>0.978202</td>\n",
              "      <td>0.977164</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2700</td>\n",
              "      <td>0.979448</td>\n",
              "      <td>0.975919</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9275</td>\n",
              "      <td>0.974673</td>\n",
              "      <td>0.976541</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3899</td>\n",
              "      <td>0.974881</td>\n",
              "      <td>0.976541</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4951</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.963463</td>\n",
              "      <td>0.959726</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2395</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.958273</td>\n",
              "      <td>0.959934</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3749</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.964708</td>\n",
              "      <td>0.958896</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2986</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.962425</td>\n",
              "      <td>0.959726</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.962217</td>\n",
              "      <td>0.959726</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4657</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.965539</td>\n",
              "      <td>0.958688</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7258</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.961387</td>\n",
              "      <td>0.960556</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.963670</td>\n",
              "      <td>0.959103</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9275</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.959311</td>\n",
              "      <td>0.959311</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.959311</td>\n",
              "      <td>0.958896</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4951</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.954328</td>\n",
              "      <td>0.950176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2395</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.957858</td>\n",
              "      <td>0.954121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3749</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.958065</td>\n",
              "      <td>0.953706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2986</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.953083</td>\n",
              "      <td>0.955366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.954744</td>\n",
              "      <td>0.952252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4657</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.956197</td>\n",
              "      <td>0.956197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7258</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.957235</td>\n",
              "      <td>0.954536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2700</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.955366</td>\n",
              "      <td>0.952252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9275</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.956612</td>\n",
              "      <td>0.957650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3899</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.955574</td>\n",
              "      <td>0.953913</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b485ceee-4332-4f37-9f24-c8a95ed67353')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b485ceee-4332-4f37-9f24-c8a95ed67353 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b485ceee-4332-4f37-9f24-c8a95ed67353');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "f = pd.concat([df_astro_m1, df_astro_m2,df_astro_m3])\n",
        "f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "id": "n-GzYOSybYqa",
        "outputId": "661bd35d-48ca-4153-c27c-17679ba38c0b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-853a29c6d38e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-9487d99134a2>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(y_test, prediction_test)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0max_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Healthy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Healthy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_axes\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                 raise ValueError('all entries in rect must be finite '\n\u001b[1;32m    623\u001b[0m                                  'not {}'.format(rect))\n",
            "\u001b[0;31mTypeError\u001b[0m: ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot(y_test, prediction_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Creating Plots**"
      ],
      "metadata": {
        "id": "2Xlwx7zhgBaT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDGIcsQbkruT"
      },
      "outputs": [],
      "source": [
        "#4. Re-run Logistic Regression with the seed that generates the highest acc to draw plot\n",
        "chosenseedm1=df_astro_m1['Seed'][df_astro_m1['aLR m1 test'].idxmax()]\n",
        "if 'X_pca' in adata_m1.obsm:\n",
        "  X = adata_m1.obsm['X_pca'].X\n",
        "else:\n",
        "  X = adata_m1.X \n",
        "    \n",
        "y = adata_m1.obs['disease__ontology_label'].replace({\"normal\": \"0\", \"Parkinson disease\": \"1\"})\n",
        "\n",
        "#2. Train-test split: 60/20/20. Random_state is the seed.Validation used for hyperparameter tuning. \n",
        "#   Parameters for the highest accuracy can be used for test set.\n",
        "  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #test is always the same\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state= chosenseedm1)\n",
        "\n",
        "prediction_test, accuracy_test = logisticRegressionTest()\n",
        "\n",
        "plot(y_test, prediction_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTYnkmAjgcL0"
      },
      "outputs": [],
      "source": [
        "# #there is error!!!\n",
        "# def logisticRegression_final_evaluation(seed):\n",
        "#   if 'X_pca' in adata_m1.obsm:\n",
        "#     X = pd.DataFrame(adata_m1.obsm['X_pca'])\n",
        "#   else:\n",
        "#     X = adata_m1.X \n",
        "    \n",
        "#   y = adata_m1.obs['disease__ontology_label'].replace({\"normal\": \"0\", \"Parkinson disease\": \"1\"})\n",
        "\n",
        "#   #2. Train-test split: 60/20/20. Random_state is the seed.Validation used for hyperparameter tuning. \n",
        "#   #   Parameters for the highest accuracy can be used for test set.\n",
        "  \n",
        "#   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #test is always the same\n",
        "#   X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state= seed)\n",
        "\n",
        "#   prediction_test, accuracy_test = logisticRegressionTest()\n",
        "#   return prediction_test, accuracy_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bkFEpwLpg5x"
      },
      "outputs": [],
      "source": [
        "#4. method 2\n",
        "chosenseedm2=df_astro_m2['Seed'][df_astro_m2['aLR m2 test'].idxmax()]\n",
        "print(chosenseedm2)\n",
        "if 'X_pca' in adata_m2.obsm:\n",
        "  X = adata_m2.obsm['X_pca'].X\n",
        "else:\n",
        "  X = adata_m2.X \n",
        "    \n",
        "y = adata_m2.obs['disease__ontology_label'].replace({\"normal\": \"0\", \"Parkinson disease\": \"1\"})\n",
        "\n",
        "#2. Train-test split: 60/20/20. Random_state is the seed.Validation used for hyperparameter tuning. \n",
        "#   Parameters for the highest accuracy can be used for test set.\n",
        "  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #test is always the same\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state= chosenseedm2)\n",
        "\n",
        "prediction_test, accuracy_test = logisticRegressionTest()\n",
        "prediction_test.astype('float64')\n",
        "y_test.astype('float64')\n",
        "plot(y_test, prediction_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcRac4rnpvSQ"
      },
      "outputs": [],
      "source": [
        "#4. method 3\n",
        "chosenseedm3=df_astro_m3['Seed'][df_astro_m3['aLR m3 test'].idxmax()]\n",
        "if 'X_pca' in adata_m3.obsm:\n",
        "  X = pd.DataFrame(adata_m3.obsm['X_pca'])\n",
        "else:\n",
        "  X = adata_m3.X \n",
        "    \n",
        "y = adata_m3.obs['disease__ontology_label'].replace({\"normal\": \"0\", \"Parkinson disease\": \"1\"})\n",
        "\n",
        "#2. Train-test split: 60/20/20. Random_state is the seed.Validation used for hyperparameter tuning. \n",
        "#   Parameters for the highest accuracy can be used for test set.\n",
        "  \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #test is always the same\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state= chosenseedm3)\n",
        "\n",
        "prediction_test, accuracy_test = logisticRegressionTest()\n",
        "plot(y_test, prediction_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhDXcgJtPhoYHvCZe5rxAC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}