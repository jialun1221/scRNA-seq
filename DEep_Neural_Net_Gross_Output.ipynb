{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jialun1221/scRNA-seq/blob/main/DEep_Neural_Net_Gross_Output.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJo2ZerTq-Uf"
      },
      "outputs": [],
      "source": [
        "!pip3 install scanpy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scanpy as sc\n",
        "import sys\n",
        "from sklearn import preprocessing \n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import importlib\n",
        "required_libraries = ['torch', 'torchvision', 'PIL', 'matplotlib', \n",
        "                      'numpy', 'pandas']\n",
        "for lib in required_libraries:\n",
        "    if importlib.util.find_spec(lib) is None:\n",
        "        print(\"%s unavailable\" % lib)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Viub6Hq_YIK"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLmlNWphKIpc",
        "outputId": "2b36eead-e65a-48e9-85a2-0a70c93ed8d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpV-AsSHOf-4"
      },
      "outputs": [],
      "source": [
        "#m1\n",
        "adata = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/DAN_PC_all_genes_qc.h5ad\")\n",
        "adata.obs = adata.obs.reset_index() #reset the index for X, so the column number starts from 0\n",
        "\n",
        "X = adata.obsm[\"X_pca\"].X\n",
        "y = adata.obs['disease__ontology_label'].replace({\"normal\": \"0\", \"Parkinson disease\": \"1\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWDVlpEhcQU9"
      },
      "outputs": [],
      "source": [
        "#m2\n",
        "adata = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/DAN_PC_HVGs_qc.h5ad\")\n",
        "adata.obs = adata.obs.reset_index() #reset the index for X, so the column number starts from 0\n",
        "\n",
        "X = adata.X\n",
        "y = adata.obs['disease__ontology_label'].replace({\"normal\": \"0\", \"Parkinson disease\": \"1\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ex_wLnFcNrL"
      },
      "outputs": [],
      "source": [
        "#m3\n",
        "adata = sc.read_h5ad(\"drive/MyDrive/scRNA ML classifier/data_objects_May_2022/DAN_no_PC_HVGs_qc.h5ad\")\n",
        "adata.obs = adata.obs.reset_index() #reset the index for X, so the column number starts from 0\n",
        "\n",
        "X = adata.X\n",
        "y = adata.obs['disease__ontology_label'].replace({\"normal\": \"0\", \"Parkinson disease\": \"1\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-wnpcdcy8lv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import scanpy as sc\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "# seed = 4321\n",
        "# np.random.seed(seed) # Set the random seed of numpy for the data split.\n",
        "# torch.manual_seed(seed)\n",
        "# torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTenrDuQ5S3y"
      },
      "outputs": [],
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeLUepTo4np8"
      },
      "outputs": [],
      "source": [
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pHHM-4rvgS2"
      },
      "source": [
        "I got everthing :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tozHiLApvSSt"
      },
      "outputs": [],
      "source": [
        "#the real train and test dataset\n",
        "# train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "# val_dataset = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
        "# test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsBhh2eTMuRD"
      },
      "source": [
        "####Set up the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt1wt4oxzzxu"
      },
      "outputs": [],
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(NeuralNet, self).__init__()\n",
        "      self.n = X_train.shape[1] #number of rows\n",
        "        \n",
        "      self.fc1 = nn.Linear(self.n, int(self.n/2))\n",
        "      self.fc2 = nn.Linear(int(self.n/2), int(self.n/4))\n",
        "      #self.fc3 = nn.Linear(int(len(X_train)/4),int(len(X_train)/8))\n",
        "      self.output = nn.Linear(int(self.n/4), 2)\n",
        "        \n",
        "      # this are defining the layers and the hyper paramters that means the \n",
        "      # conditions to compare\n",
        "    \n",
        "    def forward(self, x):      \n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = F.relu(self.fc2(x))\n",
        "      #x = F.relu(self.fc3(x))\n",
        "      out = self.output(x)   # the RelU is non linearity that removes all negative values and shouldn't be used right before softmax\n",
        "      return out\n",
        "\n",
        "    def print(self):\n",
        "        return self.fc1\n",
        "    \n",
        "# A = NeuralNet()\n",
        "# A.print()\n",
        "      # here we are telling the model how to pass the information from on layer to the next\n",
        "      #in pytorch we do not explain the graph traveral method as this computational graph is automatically defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF80PJsez3yh"
      },
      "outputs": [],
      "source": [
        "def loss_function(prediction, target):\n",
        "    loss = F.cross_entropy(prediction, target)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86YhWjbMz6vB"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, train_loader, optimizer, device):\n",
        "    \n",
        "    # activate the training mode\n",
        "    model.train()\n",
        "    \n",
        "    torch.set_grad_enabled(True)\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    # iteration over the mini-batches\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        \n",
        "        # transfer the data on the chosen device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        target=target.float()\n",
        "\n",
        "        # reinitialize the gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward propagation on the data\n",
        "        prediction = model(data)\n",
        "        \n",
        "        # compute the loss function w.r.t. the targets \n",
        "        loss = loss_function(prediction, target)\n",
        "        \n",
        "        # execute the backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # execute an optimization step\n",
        "        optimizer.step()\n",
        "        \n",
        "        # accumulate the loss\n",
        "        total_loss += loss.item()*len(data)\n",
        "        # we multiply by the length of the data incase the last minibatch is smaller we are 'denormalizing' so that a small batch isn't overweighted\n",
        "        \n",
        "        # compute the number of correct predictions\n",
        "        _, pred_classes = torch.max(prediction, dim=1)\n",
        "        _, target_classes = torch.max(target, dim=1)\n",
        "\n",
        "        #print(pred_classes)      \n",
        "        #print(type(pred_classes))  \n",
        "        #print(pred_classes.shape)\n",
        "\n",
        "        #print(prediction.shape)\n",
        "        correct += int(pred_classes.eq(target_classes).sum().item())\n",
        "        # print('pred', prediction)\n",
        "        # print('target', target)\n",
        "        # print('correct', correct)\n",
        "        #print(prediction.shape)\n",
        "\n",
        "    # compute the average loss per epoch\n",
        "    mean_loss = total_loss/len(train_loader.dataset)\n",
        "  \n",
        "    # compute the accuracy\n",
        "    acc = correct / len(train_loader.dataset)\n",
        "\n",
        "    print('Train Epoch: {}   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
        "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
        "        100. * acc))   \n",
        "    \n",
        "    # return the average loss and the accuracy\n",
        "    return mean_loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ek3ckGwz73b"
      },
      "outputs": [],
      "source": [
        "# Evaluation Procedure\n",
        "def evaluate(model, eval_loader, device):\n",
        "    \n",
        "    # activate the evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    # we don't need to compute the gradient graph it using too much compuatation\n",
        "        # iterate over the batches\n",
        "        for batch_idx, (data, target) in enumerate(eval_loader):\n",
        "\n",
        "            # transfer the data on the chosen device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            target=target.float()\n",
        "\n",
        "            # forward propagation on the data\n",
        "            prediction = model(data)\n",
        "\n",
        "            # compute the loss function w.r.t. the targets\n",
        "            loss = loss_function(prediction, target)           \n",
        "\n",
        "            # accumulate the loss\n",
        "            total_loss += loss.item()*len(data)\n",
        "\n",
        "            # compute the number of correct predictions en sortie)\n",
        "            _, pred_classes = torch.max(prediction, dim=1)\n",
        "            _, target_classes = torch.max(target, dim=1)\n",
        "\n",
        "            correct += int(pred_classes.eq(target_classes).sum().item())         \n",
        "          \n",
        "    # compute the average loss per epoch\n",
        "    mean_loss = total_loss/len(eval_loader.dataset)\n",
        "    \n",
        "    # compute the accuracy\n",
        "    acc = correct / len(eval_loader.dataset)\n",
        "\n",
        "    print('Eval:  Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
        "        mean_loss, correct, len(eval_loader.dataset),\n",
        "        100. * acc)) \n",
        "    \n",
        "    # return the average loss and the accuracy\n",
        "    return mean_loss, acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1UPv-yaz9ZF"
      },
      "outputs": [],
      "source": [
        "def save_model(epoch, model, path='./'):\n",
        "    \n",
        "    # creating the file name indexed by the epoch value\n",
        "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
        "    \n",
        "    # saving the model parameters\n",
        "    torch.save(model.state_dict(), filename)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxKebOv9z-QV"
      },
      "outputs": [],
      "source": [
        "def load_model(epoch, model, path='./'):\n",
        "    \n",
        "    # creating the file name indexed by the epoch value\n",
        "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
        "    \n",
        "    # loading the parameters of the saved model\n",
        "    model.load_state_dict(torch.load(filename))\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wP0uQrQJFFj"
      },
      "outputs": [],
      "source": [
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qE7nOdKOvgVD",
        "outputId": "2665db0b-0979-4ed6-970b-80fa6ba920af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seed:  5825\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[ 0.1583,  0.0552],\n",
            "        [-0.0488, -0.0885],\n",
            "        [ 0.1020,  0.0919],\n",
            "        [ 0.0738,  0.1464],\n",
            "        [ 0.0443,  0.0550]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.5258, 0.4742],\n",
            "        [0.5099, 0.4901],\n",
            "        [0.5025, 0.4975],\n",
            "        [0.4818, 0.5182],\n",
            "        [0.4973, 0.5027]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([0, 0, 0, 1, 1])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09587   Acc: 14463/15011 (96.349%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:18<04:22, 18.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.05990   Acc: 4918/5004 (98.281%)\n",
            "Train Epoch: 2   Avg_Loss: 0.02011   Acc: 14935/15011 (99.494%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:39<04:16, 19.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.07107   Acc: 4915/5004 (98.221%)\n",
            "Train Epoch: 3   Avg_Loss: 0.00454   Acc: 14991/15011 (99.867%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:05<04:30, 22.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.12549   Acc: 4851/5004 (96.942%)\n",
            "Train Epoch: 4   Avg_Loss: 0.01402   Acc: 14946/15011 (99.567%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:32<04:30, 24.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.14240   Acc: 4905/5004 (98.022%)\n",
            "Train Epoch: 5   Avg_Loss: 0.01825   Acc: 14953/15011 (99.614%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:01<04:19, 25.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.09067   Acc: 4901/5004 (97.942%)\n",
            "Train Epoch: 6   Avg_Loss: 0.01024   Acc: 14966/15011 (99.700%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:33<04:13, 28.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13297   Acc: 4892/5004 (97.762%)\n",
            "Train Epoch: 7   Avg_Loss: 0.00188   Acc: 15000/15011 (99.927%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:07<04:01, 30.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11998   Acc: 4910/5004 (98.122%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00028   Acc: 15010/15011 (99.993%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [03:43<03:43, 31.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.12685   Acc: 4913/5004 (98.181%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00001   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:20<03:20, 33.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13589   Acc: 4919/5004 (98.301%)\n",
            "Train Epoch: 10   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [04:59<02:55, 35.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.15118   Acc: 4921/5004 (98.341%)\n",
            "Train Epoch: 11   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [05:40<02:27, 36.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16495   Acc: 4921/5004 (98.341%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:22<01:55, 38.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.17432   Acc: 4921/5004 (98.341%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:04<01:19, 39.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.18304   Acc: 4920/5004 (98.321%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [07:47<00:40, 40.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.19205   Acc: 4920/5004 (98.321%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:30<00:00, 34.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.19881   Acc: 4919/5004 (98.301%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 1.6318e-11],\n",
            "        [1.0000e+00, 3.9627e-21],\n",
            "        [3.3003e-18, 1.0000e+00],\n",
            "        [1.0000e+00, 2.2023e-15],\n",
            "        [3.6515e-16, 1.0000e+00],\n",
            "        [1.0516e-27, 1.0000e+00],\n",
            "        [1.0905e-24, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 3.3727e-12],\n",
            "        [1.0000e+00, 6.1657e-43]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.19881   Acc: 4919/5004 (98.301%)\n",
            "Eval:  Avg_Loss: 0.29940   Acc: 4901/5004 (97.942%)\n",
            "seed:  9955\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[ 0.0617,  0.0993],\n",
            "        [-0.0318,  0.0070],\n",
            "        [ 0.0415,  0.0119],\n",
            "        [-0.0060, -0.0482],\n",
            "        [ 0.0348,  0.0036]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.4906, 0.5094],\n",
            "        [0.4903, 0.5097],\n",
            "        [0.5074, 0.4926],\n",
            "        [0.5105, 0.4895],\n",
            "        [0.5078, 0.4922]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([1, 1, 0, 0, 0])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09408   Acc: 14527/15011 (96.776%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:18<04:19, 18.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.06234   Acc: 4909/5004 (98.102%)\n",
            "Train Epoch: 2   Avg_Loss: 0.01314   Acc: 14944/15011 (99.554%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:40<04:26, 20.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.09585   Acc: 4891/5004 (97.742%)\n",
            "Train Epoch: 3   Avg_Loss: 0.00816   Acc: 14974/15011 (99.754%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:03<04:22, 21.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.10639   Acc: 4886/5004 (97.642%)\n",
            "Train Epoch: 4   Avg_Loss: 0.01680   Acc: 14970/15011 (99.727%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:34<04:37, 25.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11340   Acc: 4890/5004 (97.722%)\n",
            "Train Epoch: 5   Avg_Loss: 0.01666   Acc: 14944/15011 (99.554%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:06<04:38, 27.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13752   Acc: 4901/5004 (97.942%)\n",
            "Train Epoch: 6   Avg_Loss: 0.00834   Acc: 14973/15011 (99.747%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:39<04:25, 29.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13085   Acc: 4902/5004 (97.962%)\n",
            "Train Epoch: 7   Avg_Loss: 0.00294   Acc: 15002/15011 (99.940%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:17<04:17, 32.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.15817   Acc: 4910/5004 (98.122%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00033   Acc: 15009/15011 (99.987%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [03:56<04:00, 34.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16774   Acc: 4909/5004 (98.102%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00003   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:36<03:37, 36.23s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.18415   Acc: 4921/5004 (98.341%)\n",
            "Train Epoch: 10   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [05:18<03:10, 38.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.18876   Acc: 4921/5004 (98.341%)\n",
            "Train Epoch: 11   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [06:00<02:37, 39.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.19366   Acc: 4918/5004 (98.281%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:43<02:01, 40.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.19823   Acc: 4917/5004 (98.261%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:28<01:23, 41.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.20244   Acc: 4917/5004 (98.261%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [08:12<00:42, 42.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.20669   Acc: 4916/5004 (98.241%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:57<00:00, 35.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21078   Acc: 4915/5004 (98.221%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 2.5733e-16],\n",
            "        [1.0000e+00, 3.7548e-26],\n",
            "        [3.0894e-10, 1.0000e+00],\n",
            "        [1.0000e+00, 1.5492e-08],\n",
            "        [2.2795e-07, 1.0000e+00],\n",
            "        [6.3378e-24, 1.0000e+00],\n",
            "        [3.7972e-26, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 6.3367e-09],\n",
            "        [1.0000e+00, 1.4013e-45]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21078   Acc: 4915/5004 (98.221%)\n",
            "Eval:  Avg_Loss: 0.27665   Acc: 4903/5004 (97.982%)\n",
            "seed:  656\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[ 0.0928,  0.0678],\n",
            "        [ 0.1493,  0.0004],\n",
            "        [ 0.0816, -0.0142],\n",
            "        [ 0.0161, -0.0729],\n",
            "        [ 0.1120, -0.0576]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.5062, 0.4938],\n",
            "        [0.5371, 0.4629],\n",
            "        [0.5240, 0.4760],\n",
            "        [0.5222, 0.4778],\n",
            "        [0.5423, 0.4577]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([0, 0, 0, 0, 0])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.10134   Acc: 14450/15011 (96.263%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:18<04:23, 18.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.05132   Acc: 4902/5004 (97.962%)\n",
            "Train Epoch: 2   Avg_Loss: 0.01720   Acc: 14928/15011 (99.447%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:41<04:37, 21.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.05500   Acc: 4919/5004 (98.301%)\n",
            "Train Epoch: 3   Avg_Loss: 0.00946   Acc: 14957/15011 (99.640%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:09<04:50, 24.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.08800   Acc: 4892/5004 (97.762%)\n",
            "Train Epoch: 4   Avg_Loss: 0.01904   Acc: 14934/15011 (99.487%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:38<04:48, 26.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.04994   Acc: 4919/5004 (98.301%)\n",
            "Train Epoch: 5   Avg_Loss: 0.01331   Acc: 14968/15011 (99.714%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:08<04:33, 27.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.06192   Acc: 4903/5004 (97.982%)\n",
            "Train Epoch: 6   Avg_Loss: 0.00675   Acc: 14983/15011 (99.813%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:40<04:20, 28.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.26772   Acc: 4890/5004 (97.722%)\n",
            "Train Epoch: 7   Avg_Loss: 0.01399   Acc: 14976/15011 (99.767%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:18<04:15, 31.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11327   Acc: 4908/5004 (98.082%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00619   Acc: 14991/15011 (99.867%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [03:54<03:53, 33.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.10088   Acc: 4914/5004 (98.201%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00541   Acc: 14995/15011 (99.893%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:31<03:25, 34.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.18468   Acc: 4887/5004 (97.662%)\n",
            "Train Epoch: 10   Avg_Loss: 0.03037   Acc: 14946/15011 (99.567%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [05:07<02:53, 34.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11658   Acc: 4916/5004 (98.241%)\n",
            "Train Epoch: 11   Avg_Loss: 0.01292   Acc: 14984/15011 (99.820%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [05:44<02:22, 35.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11537   Acc: 4908/5004 (98.082%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00142   Acc: 15005/15011 (99.960%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:21<01:47, 35.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.14867   Acc: 4919/5004 (98.301%)\n",
            "Train Epoch: 13   Avg_Loss: 0.02824   Acc: 14978/15011 (99.780%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:00<01:13, 36.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.23140   Acc: 4912/5004 (98.161%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00473   Acc: 14993/15011 (99.880%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [07:40<00:37, 37.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21631   Acc: 4922/5004 (98.361%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00038   Acc: 15009/15011 (99.987%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:19<00:00, 33.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.25034   Acc: 4916/5004 (98.241%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 7.1565e-17],\n",
            "        [1.0000e+00, 4.9869e-36],\n",
            "        [3.3888e-19, 1.0000e+00],\n",
            "        [1.0000e+00, 1.6678e-22],\n",
            "        [5.8445e-12, 1.0000e+00],\n",
            "        [2.9069e-40, 1.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.9879e-18],\n",
            "        [1.0000e+00, 0.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.25034   Acc: 4916/5004 (98.241%)\n",
            "Eval:  Avg_Loss: 0.46736   Acc: 4892/5004 (97.762%)\n",
            "seed:  9564\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[ 0.0631, -0.0429],\n",
            "        [ 0.0381, -0.0518],\n",
            "        [ 0.0476,  0.0221],\n",
            "        [ 0.0627, -0.1216],\n",
            "        [-0.0539,  0.0107]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.5265, 0.4735],\n",
            "        [0.5225, 0.4775],\n",
            "        [0.5064, 0.4936],\n",
            "        [0.5459, 0.4541],\n",
            "        [0.4839, 0.5161]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([0, 0, 0, 0, 1])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09625   Acc: 14465/15011 (96.363%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:19<04:33, 19.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.06102   Acc: 4902/5004 (97.962%)\n",
            "Train Epoch: 2   Avg_Loss: 0.01633   Acc: 14928/15011 (99.447%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:41<04:32, 20.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.09210   Acc: 4885/5004 (97.622%)\n",
            "Train Epoch: 3   Avg_Loss: 0.01065   Acc: 14962/15011 (99.674%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:07<04:41, 23.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.09935   Acc: 4913/5004 (98.181%)\n",
            "Train Epoch: 4   Avg_Loss: 0.00855   Acc: 14967/15011 (99.707%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:35<04:36, 25.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.15614   Acc: 4874/5004 (97.402%)\n",
            "Train Epoch: 5   Avg_Loss: 0.00759   Acc: 14980/15011 (99.793%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:04<04:25, 26.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13309   Acc: 4893/5004 (97.782%)\n",
            "Train Epoch: 6   Avg_Loss: 0.01351   Acc: 14970/15011 (99.727%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:37<04:17, 28.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.15008   Acc: 4880/5004 (97.522%)\n",
            "Train Epoch: 7   Avg_Loss: 0.01195   Acc: 14979/15011 (99.787%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:09<03:59, 29.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.28605   Acc: 4899/5004 (97.902%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00799   Acc: 14982/15011 (99.807%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [03:50<03:53, 33.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16563   Acc: 4901/5004 (97.942%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00557   Acc: 14990/15011 (99.860%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:32<03:35, 35.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.14147   Acc: 4913/5004 (98.181%)\n",
            "Train Epoch: 10   Avg_Loss: 0.02475   Acc: 14976/15011 (99.767%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [05:12<03:06, 37.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.30695   Acc: 4887/5004 (97.662%)\n",
            "Train Epoch: 11   Avg_Loss: 0.02265   Acc: 14944/15011 (99.554%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [05:52<02:32, 38.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21388   Acc: 4899/5004 (97.902%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00953   Acc: 14990/15011 (99.860%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:33<01:57, 39.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.14941   Acc: 4900/5004 (97.922%)\n",
            "Train Epoch: 13   Avg_Loss: 0.01643   Acc: 14991/15011 (99.867%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:11<01:17, 38.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.42286   Acc: 4886/5004 (97.642%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00890   Acc: 14995/15011 (99.893%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [07:54<00:39, 39.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.23541   Acc: 4919/5004 (98.301%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00169   Acc: 15004/15011 (99.953%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:36<00:00, 34.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.35664   Acc: 4908/5004 (98.082%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 2.1167e-28],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.8712e-09, 1.0000e+00],\n",
            "        [1.0000e+00, 1.5852e-28],\n",
            "        [1.6629e-10, 1.0000e+00],\n",
            "        [3.2597e-28, 1.0000e+00],\n",
            "        [7.4764e-29, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 5.7880e-36],\n",
            "        [1.0000e+00, 0.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.35664   Acc: 4908/5004 (98.082%)\n",
            "Eval:  Avg_Loss: 0.50140   Acc: 4895/5004 (97.822%)\n",
            "seed:  5739\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[ 0.0959, -0.0029],\n",
            "        [ 0.0895,  0.0740],\n",
            "        [-0.0369,  0.0807],\n",
            "        [ 0.0207, -0.0841],\n",
            "        [ 0.0662,  0.0269]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.5247, 0.4753],\n",
            "        [0.5039, 0.4961],\n",
            "        [0.4706, 0.5294],\n",
            "        [0.5262, 0.4738],\n",
            "        [0.5098, 0.4902]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([0, 0, 1, 0, 0])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09638   Acc: 14505/15011 (96.629%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:20<04:47, 20.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.05276   Acc: 4917/5004 (98.261%)\n",
            "Train Epoch: 2   Avg_Loss: 0.02223   Acc: 14922/15011 (99.407%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:43<04:46, 22.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.08996   Acc: 4882/5004 (97.562%)\n",
            "Train Epoch: 3   Avg_Loss: 0.01352   Acc: 14962/15011 (99.674%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:10<04:50, 24.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.07560   Acc: 4900/5004 (97.922%)\n",
            "Train Epoch: 4   Avg_Loss: 0.01756   Acc: 14976/15011 (99.767%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:39<04:49, 26.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.08732   Acc: 4906/5004 (98.042%)\n",
            "Train Epoch: 5   Avg_Loss: 0.00673   Acc: 14981/15011 (99.800%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:09<04:35, 27.56s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.10962   Acc: 4914/5004 (98.201%)\n",
            "Train Epoch: 6   Avg_Loss: 0.00631   Acc: 14992/15011 (99.873%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:46<04:35, 30.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.09086   Acc: 4928/5004 (98.481%)\n",
            "Train Epoch: 7   Avg_Loss: 0.00356   Acc: 14993/15011 (99.880%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:22<04:18, 32.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11512   Acc: 4910/5004 (98.122%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00277   Acc: 14997/15011 (99.907%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [04:00<03:59, 34.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11895   Acc: 4927/5004 (98.461%)\n",
            "Train Epoch: 9   Avg_Loss: 0.01025   Acc: 14982/15011 (99.807%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:38<03:31, 35.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.40503   Acc: 4886/5004 (97.642%)\n",
            "Train Epoch: 10   Avg_Loss: 0.02669   Acc: 14938/15011 (99.514%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [05:12<02:55, 35.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.20463   Acc: 4906/5004 (98.042%)\n",
            "Train Epoch: 11   Avg_Loss: 0.04391   Acc: 14950/15011 (99.594%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [05:50<02:23, 35.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21288   Acc: 4920/5004 (98.321%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00667   Acc: 14990/15011 (99.860%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:28<01:50, 36.72s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.18926   Acc: 4920/5004 (98.321%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00755   Acc: 14990/15011 (99.860%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:08<01:15, 37.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.32657   Acc: 4917/5004 (98.261%)\n",
            "Train Epoch: 14   Avg_Loss: 0.05025   Acc: 14966/15011 (99.700%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [07:44<00:37, 37.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.47494   Acc: 4885/5004 (97.622%)\n",
            "Train Epoch: 15   Avg_Loss: 0.01240   Acc: 14986/15011 (99.833%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:23<00:00, 33.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21326   Acc: 4929/5004 (98.501%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 1.1971e-19],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [8.8008e-35, 1.0000e+00],\n",
            "        [1.0000e+00, 4.1693e-20],\n",
            "        [4.3541e-32, 1.0000e+00],\n",
            "        [0.0000e+00, 1.0000e+00],\n",
            "        [6.4238e-28, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 2.2891e-20],\n",
            "        [1.0000e+00, 0.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21326   Acc: 4929/5004 (98.501%)\n",
            "Eval:  Avg_Loss: 0.45441   Acc: 4895/5004 (97.822%)\n",
            "seed:  8412\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[-0.0217,  0.0945],\n",
            "        [-0.0920,  0.1582],\n",
            "        [-0.0888,  0.0818],\n",
            "        [-0.0533, -0.0288],\n",
            "        [-0.0346,  0.0167]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.4710, 0.5290],\n",
            "        [0.4378, 0.5622],\n",
            "        [0.4574, 0.5426],\n",
            "        [0.4939, 0.5061],\n",
            "        [0.4872, 0.5128]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([1, 1, 1, 1, 1])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09267   Acc: 14509/15011 (96.656%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:19<04:37, 19.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.05856   Acc: 4905/5004 (98.022%)\n",
            "Train Epoch: 2   Avg_Loss: 0.01899   Acc: 14915/15011 (99.360%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:40<04:23, 20.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.06779   Acc: 4909/5004 (98.102%)\n",
            "Train Epoch: 3   Avg_Loss: 0.00774   Acc: 14979/15011 (99.787%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:06<04:35, 22.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.14444   Acc: 4888/5004 (97.682%)\n",
            "Train Epoch: 4   Avg_Loss: 0.01763   Acc: 14940/15011 (99.527%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:32<04:26, 24.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11715   Acc: 4899/5004 (97.902%)\n",
            "Train Epoch: 5   Avg_Loss: 0.00999   Acc: 14970/15011 (99.727%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:04<04:28, 26.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13935   Acc: 4872/5004 (97.362%)\n",
            "Train Epoch: 6   Avg_Loss: 0.01445   Acc: 14950/15011 (99.594%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:39<04:26, 29.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13906   Acc: 4891/5004 (97.742%)\n",
            "Train Epoch: 7   Avg_Loss: 0.02501   Acc: 14964/15011 (99.687%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:15<04:15, 31.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13377   Acc: 4916/5004 (98.241%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00294   Acc: 14989/15011 (99.853%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [03:53<03:55, 33.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16454   Acc: 4913/5004 (98.181%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00042   Acc: 15009/15011 (99.987%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:33<03:33, 35.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.18913   Acc: 4909/5004 (98.102%)\n",
            "Train Epoch: 10   Avg_Loss: 0.00001   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [05:15<03:08, 37.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.20156   Acc: 4910/5004 (98.122%)\n",
            "Train Epoch: 11   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [05:58<02:36, 39.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.20729   Acc: 4911/5004 (98.141%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:41<02:01, 40.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21240   Acc: 4910/5004 (98.122%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:26<01:23, 41.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21734   Acc: 4910/5004 (98.122%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [08:09<00:42, 42.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.22254   Acc: 4911/5004 (98.141%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:54<00:00, 35.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.23204   Acc: 4913/5004 (98.181%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 1.2312e-14],\n",
            "        [1.0000e+00, 2.7727e-41],\n",
            "        [4.3910e-17, 1.0000e+00],\n",
            "        [1.0000e+00, 2.7057e-16],\n",
            "        [1.5233e-10, 1.0000e+00],\n",
            "        [5.7612e-23, 1.0000e+00],\n",
            "        [8.3846e-22, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 3.5271e-08],\n",
            "        [1.0000e+00, 0.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.23204   Acc: 4913/5004 (98.181%)\n",
            "Eval:  Avg_Loss: 0.31655   Acc: 4902/5004 (97.962%)\n",
            "seed:  5891\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[-0.0014, -0.0069],\n",
            "        [-0.0378,  0.0068],\n",
            "        [ 0.0414, -0.0160],\n",
            "        [-0.0273, -0.0162],\n",
            "        [ 0.0566, -0.0652]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.5014, 0.4986],\n",
            "        [0.4889, 0.5111],\n",
            "        [0.5144, 0.4856],\n",
            "        [0.4972, 0.5028],\n",
            "        [0.5304, 0.4696]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([0, 1, 0, 1, 0])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09659   Acc: 14493/15011 (96.549%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:19<04:32, 19.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.05151   Acc: 4915/5004 (98.221%)\n",
            "Train Epoch: 2   Avg_Loss: 0.01763   Acc: 14939/15011 (99.520%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:44<04:54, 22.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.08875   Acc: 4889/5004 (97.702%)\n",
            "Train Epoch: 3   Avg_Loss: 0.00635   Acc: 14979/15011 (99.787%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:14<05:10, 25.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.07039   Acc: 4917/5004 (98.261%)\n",
            "Train Epoch: 4   Avg_Loss: 0.00812   Acc: 14979/15011 (99.787%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:42<04:55, 26.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.07913   Acc: 4902/5004 (97.962%)\n",
            "Train Epoch: 5   Avg_Loss: 0.01019   Acc: 14967/15011 (99.707%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:09<04:29, 26.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.09571   Acc: 4907/5004 (98.062%)\n",
            "Train Epoch: 6   Avg_Loss: 0.03547   Acc: 14926/15011 (99.434%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:45<04:30, 30.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.08784   Acc: 4892/5004 (97.762%)\n",
            "Train Epoch: 7   Avg_Loss: 0.00662   Acc: 14982/15011 (99.807%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:17<04:05, 30.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.09697   Acc: 4912/5004 (98.161%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00183   Acc: 15002/15011 (99.940%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [03:54<03:48, 32.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.14319   Acc: 4910/5004 (98.122%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00012   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:34<03:29, 34.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16303   Acc: 4907/5004 (98.062%)\n",
            "Train Epoch: 10   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [05:17<03:06, 37.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16091   Acc: 4909/5004 (98.102%)\n",
            "Train Epoch: 11   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [06:00<02:36, 39.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16145   Acc: 4908/5004 (98.082%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:43<02:01, 40.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16218   Acc: 4907/5004 (98.062%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:28<01:23, 41.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16318   Acc: 4907/5004 (98.062%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [08:12<00:42, 42.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16434   Acc: 4907/5004 (98.062%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:56<00:00, 35.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16559   Acc: 4907/5004 (98.062%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 6.5868e-13],\n",
            "        [1.0000e+00, 1.7182e-22],\n",
            "        [2.9783e-12, 1.0000e+00],\n",
            "        [1.0000e+00, 1.5056e-17],\n",
            "        [6.5716e-19, 1.0000e+00],\n",
            "        [1.3437e-22, 1.0000e+00],\n",
            "        [4.1161e-25, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 9.7000e-20],\n",
            "        [1.0000e+00, 7.0065e-44]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16559   Acc: 4907/5004 (98.062%)\n",
            "Eval:  Avg_Loss: 0.25129   Acc: 4916/5004 (98.241%)\n",
            "seed:  521\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[ 0.0751,  0.0310],\n",
            "        [ 0.1375,  0.1006],\n",
            "        [ 0.0837,  0.0105],\n",
            "        [ 0.0749,  0.0684],\n",
            "        [ 0.0605, -0.0119]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.5110, 0.4890],\n",
            "        [0.5092, 0.4908],\n",
            "        [0.5183, 0.4817],\n",
            "        [0.5016, 0.4984],\n",
            "        [0.5181, 0.4819]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([0, 0, 0, 0, 0])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09862   Acc: 14469/15011 (96.389%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:19<04:34, 19.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.04955   Acc: 4903/5004 (97.982%)\n",
            "Train Epoch: 2   Avg_Loss: 0.01560   Acc: 14943/15011 (99.547%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:41<04:32, 20.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.06720   Acc: 4902/5004 (97.962%)\n",
            "Train Epoch: 3   Avg_Loss: 0.02328   Acc: 14912/15011 (99.340%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:07<04:37, 23.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.09307   Acc: 4902/5004 (97.962%)\n",
            "Train Epoch: 4   Avg_Loss: 0.00581   Acc: 14982/15011 (99.807%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:36<04:41, 25.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.08931   Acc: 4904/5004 (98.002%)\n",
            "Train Epoch: 5   Avg_Loss: 0.00130   Acc: 15002/15011 (99.940%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:06<04:30, 27.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.10506   Acc: 4912/5004 (98.161%)\n",
            "Train Epoch: 6   Avg_Loss: 0.00009   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:35<04:11, 27.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11408   Acc: 4913/5004 (98.181%)\n",
            "Train Epoch: 7   Avg_Loss: 0.00001   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:05<03:48, 28.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11659   Acc: 4913/5004 (98.181%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [03:35<03:22, 28.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.12408   Acc: 4913/5004 (98.181%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:08<03:01, 30.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.14736   Acc: 4914/5004 (98.201%)\n",
            "Train Epoch: 10   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [04:46<02:42, 32.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.16055   Acc: 4909/5004 (98.102%)\n",
            "Train Epoch: 11   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [05:27<02:21, 35.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.17321   Acc: 4911/5004 (98.141%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:12<01:54, 38.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.18417   Acc: 4911/5004 (98.141%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [06:58<01:20, 40.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.19234   Acc: 4909/5004 (98.102%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [07:44<00:42, 42.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.19923   Acc: 4906/5004 (98.042%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:31<00:00, 34.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.20607   Acc: 4907/5004 (98.062%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 1.0451e-07],\n",
            "        [1.0000e+00, 6.0304e-23],\n",
            "        [5.2073e-12, 1.0000e+00],\n",
            "        [1.0000e+00, 1.0962e-16],\n",
            "        [6.7733e-10, 1.0000e+00],\n",
            "        [5.7828e-30, 1.0000e+00],\n",
            "        [1.1255e-22, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 4.6621e-14],\n",
            "        [1.0000e+00, 4.4557e-30]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.20607   Acc: 4907/5004 (98.062%)\n",
            "Eval:  Avg_Loss: 0.30069   Acc: 4911/5004 (98.141%)\n",
            "seed:  1791\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[-0.1317,  0.0340],\n",
            "        [-0.0920,  0.1375],\n",
            "        [-0.1751, -0.0002],\n",
            "        [-0.1447,  0.0300],\n",
            "        [-0.1434, -0.0024]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.4587, 0.5413],\n",
            "        [0.4429, 0.5571],\n",
            "        [0.4564, 0.5436],\n",
            "        [0.4564, 0.5436],\n",
            "        [0.4648, 0.5352]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([1, 1, 1, 1, 1])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09126   Acc: 14499/15011 (96.589%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:19<04:26, 19.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.06245   Acc: 4892/5004 (97.762%)\n",
            "Train Epoch: 2   Avg_Loss: 0.01816   Acc: 14935/15011 (99.494%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:44<04:59, 23.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.07946   Acc: 4898/5004 (97.882%)\n",
            "Train Epoch: 3   Avg_Loss: 0.00907   Acc: 14970/15011 (99.727%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:12<05:03, 25.29s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.13241   Acc: 4891/5004 (97.742%)\n",
            "Train Epoch: 4   Avg_Loss: 0.00659   Acc: 14980/15011 (99.793%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:42<04:57, 27.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.12339   Acc: 4900/5004 (97.922%)\n",
            "Train Epoch: 5   Avg_Loss: 0.00794   Acc: 14970/15011 (99.727%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:13<04:43, 28.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.10479   Acc: 4906/5004 (98.042%)\n",
            "Train Epoch: 6   Avg_Loss: 0.01215   Acc: 14971/15011 (99.734%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:46<04:30, 30.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.15756   Acc: 4889/5004 (97.702%)\n",
            "Train Epoch: 7   Avg_Loss: 0.01046   Acc: 14967/15011 (99.707%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:22<04:16, 32.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.10420   Acc: 4905/5004 (98.022%)\n",
            "Train Epoch: 8   Avg_Loss: 0.00682   Acc: 14992/15011 (99.873%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [04:00<03:57, 33.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.24804   Acc: 4896/5004 (97.842%)\n",
            "Train Epoch: 9   Avg_Loss: 0.01689   Acc: 14969/15011 (99.720%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:38<03:31, 35.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.21063   Acc: 4895/5004 (97.822%)\n",
            "Train Epoch: 10   Avg_Loss: 0.00191   Acc: 15005/15011 (99.960%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [05:17<03:01, 36.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.20139   Acc: 4907/5004 (98.062%)\n",
            "Train Epoch: 11   Avg_Loss: 0.00103   Acc: 15005/15011 (99.960%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [05:57<02:29, 37.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.23011   Acc: 4912/5004 (98.161%)\n",
            "Train Epoch: 12   Avg_Loss: 0.00003   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:39<01:56, 38.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.24493   Acc: 4914/5004 (98.201%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:22<01:20, 40.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.25092   Acc: 4914/5004 (98.201%)\n",
            "Train Epoch: 14   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [08:07<00:41, 41.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.25938   Acc: 4914/5004 (98.201%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00000   Acc: 15011/15011 (100.000%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:50<00:00, 35.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.26895   Acc: 4912/5004 (98.161%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 3.7418e-18],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [8.7176e-08, 1.0000e+00],\n",
            "        [1.0000e+00, 2.2540e-15],\n",
            "        [1.8008e-11, 1.0000e+00],\n",
            "        [4.1876e-32, 1.0000e+00],\n",
            "        [1.9137e-23, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.4546e-07],\n",
            "        [1.0000e+00, 0.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.26895   Acc: 4912/5004 (98.161%)\n",
            "Eval:  Avg_Loss: 0.33118   Acc: 4905/5004 (98.022%)\n",
            "seed:  3550\n",
            "(15011, 2500) (5004, 2500) (15011,) (5004,)\n",
            "output tensor([[ 0.0994,  0.0238],\n",
            "        [ 0.0047,  0.0159],\n",
            "        [-0.0854,  0.0480],\n",
            "        [-0.0502,  0.1097],\n",
            "        [-0.0772, -0.0104]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[0.5189, 0.4811],\n",
            "        [0.4972, 0.5028],\n",
            "        [0.4667, 0.5333],\n",
            "        [0.4601, 0.5399],\n",
            "        [0.4833, 0.5167]], grad_fn=<SoftmaxBackward0>)\n",
            "Model prediction\n",
            "tensor([0, 1, 1, 1, 1])\n",
            "Actual data\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.09304   Acc: 14487/15011 (96.509%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 1/15 [00:18<04:16, 18.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.05630   Acc: 4917/5004 (98.261%)\n",
            "Train Epoch: 2   Avg_Loss: 0.01300   Acc: 14954/15011 (99.620%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [00:39<04:17, 19.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.07268   Acc: 4894/5004 (97.802%)\n",
            "Train Epoch: 3   Avg_Loss: 0.01122   Acc: 14965/15011 (99.694%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [01:06<04:40, 23.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.07349   Acc: 4912/5004 (98.161%)\n",
            "Train Epoch: 4   Avg_Loss: 0.01879   Acc: 14937/15011 (99.507%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [01:35<04:41, 25.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11357   Acc: 4868/5004 (97.282%)\n",
            "Train Epoch: 5   Avg_Loss: 0.02049   Acc: 14933/15011 (99.480%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [02:07<04:38, 27.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.11534   Acc: 4901/5004 (97.942%)\n",
            "Train Epoch: 6   Avg_Loss: 0.00148   Acc: 15005/15011 (99.960%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [02:44<04:38, 30.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.15534   Acc: 4892/5004 (97.762%)\n",
            "Train Epoch: 7   Avg_Loss: 0.01416   Acc: 14963/15011 (99.680%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [03:19<04:18, 32.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.29384   Acc: 4891/5004 (97.742%)\n",
            "Train Epoch: 8   Avg_Loss: 0.01963   Acc: 14958/15011 (99.647%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 53%|█████▎    | 8/15 [03:56<03:56, 33.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.34641   Acc: 4858/5004 (97.082%)\n",
            "Train Epoch: 9   Avg_Loss: 0.00778   Acc: 14988/15011 (99.847%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 9/15 [04:33<03:28, 34.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.17470   Acc: 4888/5004 (97.682%)\n",
            "Train Epoch: 10   Avg_Loss: 0.00122   Acc: 15006/15011 (99.967%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 10/15 [05:11<02:58, 35.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.52920   Acc: 4883/5004 (97.582%)\n",
            "Train Epoch: 11   Avg_Loss: 0.02950   Acc: 14978/15011 (99.780%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 11/15 [05:51<02:27, 36.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.35163   Acc: 4891/5004 (97.742%)\n",
            "Train Epoch: 12   Avg_Loss: 0.01527   Acc: 14977/15011 (99.773%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 12/15 [06:29<01:51, 37.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.25362   Acc: 4900/5004 (97.922%)\n",
            "Train Epoch: 13   Avg_Loss: 0.00738   Acc: 14985/15011 (99.827%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 87%|████████▋ | 13/15 [07:08<01:15, 37.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.33570   Acc: 4890/5004 (97.722%)\n",
            "Train Epoch: 14   Avg_Loss: 0.02412   Acc: 14977/15011 (99.773%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 93%|█████████▎| 14/15 [07:47<00:38, 38.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.30378   Acc: 4901/5004 (97.942%)\n",
            "Train Epoch: 15   Avg_Loss: 0.00153   Acc: 15004/15011 (99.953%)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [08:25<00:00, 33.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.32741   Acc: 4908/5004 (98.082%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n",
            "tensor([[1.0000e+00, 1.3114e-19],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [7.3679e-21, 1.0000e+00],\n",
            "        [1.0000e+00, 7.9575e-24],\n",
            "        [2.3141e-09, 1.0000e+00],\n",
            "        [4.2569e-28, 1.0000e+00],\n",
            "        [8.5881e-18, 1.0000e+00],\n",
            "        [1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 8.5516e-11],\n",
            "        [1.0000e+00, 0.0000e+00]], grad_fn=<SoftmaxBackward0>)\n",
            "Model predictions\n",
            "tensor([0, 0, 1, 0, 1, 1, 1, 0, 0, 0])\n",
            "Targets\n",
            "tensor([[1, 0],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [0, 1],\n",
            "        [1, 0],\n",
            "        [1, 0],\n",
            "        [1, 0]])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.32741   Acc: 4908/5004 (98.082%)\n",
            "Eval:  Avg_Loss: 0.46168   Acc: 4908/5004 (98.082%)\n",
            "   Seed  DNN validation acc  DNN test acc\n",
            "0  5825            0.983014      0.979416\n",
            "1  9955            0.982214      0.979816\n",
            "2   656            0.982414      0.977618\n",
            "3  9564            0.980815      0.978217\n",
            "4  5739            0.985012      0.978217\n",
            "5  8412            0.981815      0.979616\n",
            "6  5891            0.980616      0.982414\n",
            "7   521            0.980616      0.981415\n",
            "8  1791            0.981615      0.980216\n",
            "9  3550            0.980815      0.980815\n"
          ]
        }
      ],
      "source": [
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_global, X_test_global, y_train_global, y_test_global = train_test_split(X, y, test_size=0.2, random_state=0) #initial stabilized split\n",
        "\n",
        "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        "# test_lst = []\n",
        "seed_list = []\n",
        "dict_list = []\n",
        "for m in range (10):\n",
        "  X_test = copy.deepcopy(X_test_global)\n",
        "  y_test = copy.deepcopy(y_test_global)\n",
        "\n",
        "  if len(seed_list) < 10:\n",
        "    seed = random.randint(0, 9999)\n",
        "    seed_list.append(seed)\n",
        "    print(\"seed: \", seed)\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #initial stabilized split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_global, y_train_global, test_size=0.25, random_state= seed_list[m])\n",
        "    print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
        "    # test_lst.append(X_test)\n",
        "  else:\n",
        "    print(\"seed = \", seed)\n",
        "    print(seed_list[m])\n",
        "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0) #initial stabilized split\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_global, y_train_global, test_size=0.25, random_state= seed_list[m])\n",
        "    print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
        "    # test_lst.append(X_test)\n",
        "\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=0)\n",
        "\n",
        "#Take some data from test set for validation\n",
        "#Get the validation dataset splitted\n",
        "# X_val = X_test.head(499)\n",
        "# X_test = X_test.tail(1000)\n",
        "# y_val = y_test.head(499)\n",
        "# y_test = y_test.tail(1000)\n",
        "# print(X_val.shape, X_test.shape, y_val.shape, y_test.shape)\n",
        "\n",
        "  # print(type(X_val), type(X_train), type(X_test), type(y_val), type(y_train), type(y_test)\n",
        "\n",
        "  # Type conversion\n",
        "  X_val = X_val.astype(np.float64)\n",
        "  y_val = y_val.astype(np.float64)\n",
        "  # X_val = X_val.to_numpy()\n",
        "  # y_val = y_val.to_numpy()\n",
        "\n",
        "  #Note: SoftMax requires a 2x1 matrix for the label. We turn the above `y_val`, `y_train` and `y_test` numpy array into a matrix.\n",
        "  y_val = np.stack([y_val, 1-y_val])\n",
        "  y_val = y_val.transpose()\n",
        "  #print(y_val)\n",
        "\n",
        "  y_train = y_train.astype(np.float64)\n",
        "  y_train = np.stack([y_train, 1-y_train])\n",
        "  y_train = y_train.transpose()\n",
        "  #print(y_train)\n",
        "\n",
        "  y_test = y_test.astype(np.float64)\n",
        "  y_test = np.stack([y_test, 1-y_test])\n",
        "  y_test = y_test.transpose()\n",
        "  #print(y_test)\n",
        "\n",
        "  # X_train = X_train.to_numpy()\n",
        "  # X_test = X_test.to_numpy()\n",
        "\n",
        "  #the real train and test dataset\n",
        "  train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "  val_dataset = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
        "  #print('X_test Y test: ', X_test.shape, y_test.shape)\n",
        "  #print('X train Y train: ', X_train.shape, y_train.shape)\n",
        "  test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())\n",
        "\n",
        "  #SEPARATE CELL \n",
        "\n",
        "  # Model definition - we definited above here we initiate a model\n",
        "  neural_net = NeuralNet()\n",
        "  neural_net = neural_net.to(device) #We create an instance of NeuralNetwork, and move it to the device, and print its structure.\n",
        "\n",
        "  # Evaluation mode activation\n",
        "  neural_net = neural_net.eval()\n",
        "\n",
        "  # Select the first 5 data points the name of the model is data\n",
        "  data, target = test_dataset[0:5]\n",
        "\n",
        "  data = data.to(device)\n",
        "  target = target.to(device)\n",
        "\n",
        "  # Forward propagation of the data through the model\n",
        "  output = neural_net(data)   # equivalent to neural_net.forward(data)\n",
        "  print(\"output\",output)\n",
        "  # Convert the logits into probabilities with softmax function\n",
        "  output_proba = F.softmax(output,dim=1)  # the dimension is to normalize over the outcome, over rows or columns 0 will be incorrect and sum over columns\n",
        "\n",
        "  # Printing the probability\n",
        "  print(output_proba)\n",
        "  \n",
        "  _, prediction = torch.max(output_proba, dim=1)\n",
        "\n",
        "  print('Model prediction')\n",
        "  print(prediction)\n",
        "\n",
        "  # Printing the real labels\n",
        "  print(\"Actual data\")\n",
        "  print(target)\n",
        "\n",
        "  optimizer = optim.Adam(neural_net.parameters(), lr=0.001) \n",
        "\n",
        "  train_batch_size = 32  # number of data in a training batch.\n",
        "  eval_batch_size = 32   # number of data in an batch.\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "  val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=eval_batch_size, shuffle=False)\n",
        "  test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=eval_batch_size, shuffle=False)\n",
        "\n",
        "  from tqdm import tqdm\n",
        "\n",
        "  # maximum number of epoch\n",
        "  numEpochs = 15\n",
        "\n",
        "  # Saving frequency\n",
        "  checkpoint_freq = 10\n",
        "\n",
        "  # Directory for data backup - save the model during training\n",
        "  path = './'\n",
        "\n",
        "  # Accumulators of average losses obtained per epoch to visualize training curve\n",
        "  train_losses = []\n",
        "  val_losses = []\n",
        "\n",
        "  # Performance accumulators per epoch\n",
        "  train_accuracies = []\n",
        "  val_accuracies = []\n",
        "\n",
        "  # Model definition\n",
        "  neural_net = NeuralNet()\n",
        "\n",
        "  # Load the model on the chosen device\n",
        "  neural_net = neural_net.to(device)\n",
        "\n",
        "  # Optimizer definition\n",
        "  optimizer = optim.Adam(neural_net.parameters(), lr=0.001) \n",
        "  # optimizer = optim.SGD(neural_net.parameters(), lr=0.001) \n",
        "\n",
        "  # Learning loop\n",
        "  for epoch in tqdm(range(1, numEpochs + 1)):\n",
        "      \n",
        "      # train the model with the train dataset\n",
        "      # inner loop one step \n",
        "      train_loss, train_acc = train(epoch, neural_net, train_loader, optimizer, device)   \n",
        "    \n",
        "      # evaluate the model with the validation dataset\n",
        "      val_loss, val_acc = evaluate(neural_net, val_loader, device)       \n",
        "      \n",
        "      # Save the losses obtained\n",
        "      train_losses.append(train_loss)    \n",
        "      val_losses.append(val_loss)\n",
        "      \n",
        "      # Save the performances\n",
        "      train_accuracies.append(train_acc)    \n",
        "      val_accuracies.append(val_acc)\n",
        "      \n",
        "      # Checkpoint\n",
        "      if epoch % checkpoint_freq ==0:\n",
        "          save_model(epoch, neural_net, path)\n",
        "\n",
        "  # Save the model at the end of the training\n",
        "  save_model(numEpochs, neural_net, path)\n",
        "      \n",
        "  print(\"\\n\\n\\nOptimization ended.\\n\")\n",
        "\n",
        "\n",
        "  # Activate the evaluation mode\n",
        "  neural_net = neural_net.eval()\n",
        "\n",
        "  # Select the first 10 data points of the validation set\n",
        "  data, target = test_dataset[0:10]\n",
        "  data = data.to(device)\n",
        "\n",
        "  # Executing the neural network\n",
        "  output = neural_net(data)   # equivalent to neural_net.forward(data)\n",
        "\n",
        "  # Transform the output into a probability distribution with a softmax function\n",
        "  output_proba = F.softmax(output, dim=1)\n",
        "\n",
        "  # Print the probability\n",
        "  print(output_proba)    \n",
        "\n",
        "\n",
        "  # For each example, retrieve the class with the highest probability.\n",
        "  _, prediction = torch.max(output_proba, dim=1)\n",
        "\n",
        "  print(\"Model predictions\")\n",
        "  print(prediction)\n",
        "\n",
        "  print(\"Targets\")\n",
        "  print(target)\n",
        "\n",
        "  valid_loss, valid_acc = evaluate(neural_net, val_loader, device)\n",
        "  test_loss, test_acc = evaluate(neural_net, test_loader, device)\n",
        "\n",
        "  #Disctionary append \n",
        "  row_dict = {'Seed': seed_list[m], 'DNN validation acc': valid_acc, 'DNN test acc': test_acc}\n",
        "  dict_list.append(row_dict)\n",
        "\n",
        "df = pd.DataFrame.from_dict(dict_list)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0bDv1E1tRcAj",
        "outputId": "e9ffb4cf-a93e-4419-b360-a751855d038a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5174a32a-4be7-4e63-a50d-d0d5f68df82a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Seed</th>\n",
              "      <th>DNN validation acc</th>\n",
              "      <th>DNN test acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5624</td>\n",
              "      <td>0.982814</td>\n",
              "      <td>0.979416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2747</td>\n",
              "      <td>0.983613</td>\n",
              "      <td>0.978817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4103</td>\n",
              "      <td>0.984812</td>\n",
              "      <td>0.982014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7176</td>\n",
              "      <td>0.981415</td>\n",
              "      <td>0.980616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7502</td>\n",
              "      <td>0.981615</td>\n",
              "      <td>0.979816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3127</td>\n",
              "      <td>0.978617</td>\n",
              "      <td>0.978018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6877</td>\n",
              "      <td>0.983813</td>\n",
              "      <td>0.983413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8832</td>\n",
              "      <td>0.982614</td>\n",
              "      <td>0.980815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1826</td>\n",
              "      <td>0.982214</td>\n",
              "      <td>0.979217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>390</td>\n",
              "      <td>0.981215</td>\n",
              "      <td>0.975819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5174a32a-4be7-4e63-a50d-d0d5f68df82a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5174a32a-4be7-4e63-a50d-d0d5f68df82a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5174a32a-4be7-4e63-a50d-d0d5f68df82a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Seed  DNN validation acc  DNN test acc\n",
              "0  5624            0.982814      0.979416\n",
              "1  2747            0.983613      0.978817\n",
              "2  4103            0.984812      0.982014\n",
              "3  7176            0.981415      0.980616\n",
              "4  7502            0.981615      0.979816\n",
              "5  3127            0.978617      0.978018\n",
              "6  6877            0.983813      0.983413\n",
              "7  8832            0.982614      0.980815\n",
              "8  1826            0.982214      0.979217\n",
              "9   390            0.981215      0.975819"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE1WxHbYSScP"
      },
      "source": [
        "Using [Adam Optimizer](https://pythonguides.com/adam-optimizer-pytorch/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HJnrnbPRC8sA",
        "outputId": "ed186c7c-65cc-4c30-9a6a-8683268f9a36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2150   47]\n",
            " [  49 2758]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 900x900 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics._plot.confusion_matrix import ConfusionMatrixDisplay\n",
        "from sklearn.utils.multiclass import type_of_target\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# iterate over test data\n",
        "correct = 0\n",
        "for data, target in test_loader:\n",
        "        # output = A(inputs) # Feed Network\n",
        "        # print(output)\n",
        "        # print(output.shape)\n",
        "\n",
        "        # output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "        # y_pred.extend(output) # Save Prediction\n",
        "        \n",
        "        # target = target.data.cpu().numpy()\n",
        "        # target = (target[:, 1] > 0.5).astype(\"int32\")\n",
        "        # y_true.extend(target) # Save Trut\n",
        "\n",
        "        # transfer the data on the chosen device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        target=target.float()\n",
        "\n",
        "        # forward propagation on the data\n",
        "        prediction = neural_net(data)\n",
        "\n",
        "        # compute the number of correct predictions en sortie)\n",
        "        _, pred_classes = torch.max(prediction, dim=1)\n",
        "        _, target_classes = torch.max(target, dim=1)\n",
        "        y_true.extend(target_classes)\n",
        "        y_pred.extend(pred_classes)\n",
        "        correct += int(pred_classes.eq(target_classes).sum().item())\n",
        "        \n",
        "# constant for classes\n",
        "classes = ('PD','Healthy')\n",
        "\n",
        "#print(type(target))\n",
        "\n",
        "# Build confusion matrix\n",
        "cf_matrix = confusion_matrix(y_pred, y_true)\n",
        "print(cf_matrix)\n",
        "\n",
        "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "\n",
        "cmd = ConfusionMatrixDisplay(cf_matrix, display_labels=['Healthy','PD'])\n",
        "cmd.plot(cmap = 'YlGnBu', colorbar = False)\n",
        "\n",
        "#cmd.plot(cmap = 'YlGnBu', colorbar = False)\n",
        "\n",
        "fig = cmd.ax_.get_figure()\n",
        "\n",
        "fig.set_figwidth(3)\n",
        "fig.set_figheight(3)\n",
        "plt.rcParams[\"figure.dpi\"] = 300\n",
        "plt.rc('font', size=16)\n",
        "# Set the axes title font size\n",
        "plt.rc('axes', titlesize=14)\n",
        "# Set the axes labels font size\n",
        "plt.rc('axes', labelsize=14)\n",
        "# Set the font size for x tick labels\n",
        "plt.rc('xtick', labelsize=12)\n",
        "# Set the font size for y tick labels\n",
        "plt.rc('ytick', labelsize=12)\n",
        "#plt.savefig(dpi = 300, fname = 'astro_LR.png')\n",
        "#sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('output.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJqBF35hUpTO"
      },
      "source": [
        "####Create plots of the learning curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEuShUVi1v9f"
      },
      "outputs": [],
      "source": [
        "!pip install matplotlib==3.1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj8co2Aw_U8q"
      },
      "outputs": [],
      "source": [
        "#Plot\n",
        "x = list(range(len(train_losses)))\n",
        "ax = plt.subplot(111)\n",
        "\n",
        "# #Feb 5 new: set ticks, axis and spins black\n",
        "# ax.spines['left'].set_color('black')        # setting up Y-axis tick color to red\n",
        "# ax.spines['bottom'].set_color('black')\n",
        "\n",
        "# ax.xaxis.label.set_color('black')        #setting up X-axis label color to yellow\n",
        "# ax.yaxis.label.set_color('black')          #setting up Y-axis label color to blue\n",
        "\n",
        "# ax.tick_params(axis='x', colors='black')    #setting up X-axis tick color to red\n",
        "# ax.tick_params(axis='y', colors='black')  #setting up Y-axis tick color to black\n",
        "\n",
        "plt.plot(x, train_losses, 'b', label=\"Train\")\n",
        "plt.plot(x, val_losses, 'r', label=\"Validation\")\n",
        "plt.xlabel('epoch', size=16)\n",
        "plt.ylabel('Cross-entropy loss', size=16)\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "\n",
        "f = plt.figure()\n",
        "# f.set_figwidth(4)\n",
        "# f.set_figheight(4)\n",
        "\n",
        "# leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
        "# leg.get_frame().set_alpha(0.99)\n",
        "\n",
        "#Add a legend\n",
        "pos = ax.get_position()\n",
        "#ax.set_position([pos.x0, pos.y0, pos.width * 0.9, pos.height])\n",
        "# ax.legend(loc='lower center', bbox_to_anchor=(1.33, 0.91), frameon = False, fontsize = 16)\n",
        "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.5), frameon = True, fontsize = 16)\n",
        "\n",
        "plt.savefig(\"train_losses.png\", transparent = True, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibkIH0dNicVN"
      },
      "outputs": [],
      "source": [
        "x = list(range(len(train_accuracies)))\n",
        "ax = plt.subplot(111)\n",
        "\n",
        "# #Feb 5 new: set ticks, axis and spins black\n",
        "# ax.spines['left'].set_color('black')        # setting up Y-axis tick color to red\n",
        "# ax.spines['bottom'].set_color('black')\n",
        "\n",
        "# ax.xaxis.label.set_color('black')        #setting up X-axis label color to yellow\n",
        "# ax.yaxis.label.set_color('black')          #setting up Y-axis label color to blue\n",
        "\n",
        "# ax.tick_params(axis='x', colors='black')    #setting up X-axis tick color to red\n",
        "# ax.tick_params(axis='y', colors='black')  #setting up Y-axis tick color to black\n",
        "\n",
        "plt.plot(x, train_accuracies, 'b', label=\"Train\")\n",
        "plt.plot(x, val_accuracies, 'r', label=\"Validation\")\n",
        "plt.xlabel('epoch', size = 16)\n",
        "plt.ylabel('Accuracy', size = 16)\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "\n",
        "f = plt.figure()\n",
        "\n",
        "# Add a legend\n",
        "pos = ax.get_position()\n",
        "# ax.set_position([pos.x0, pos.y0, pos.width * 0.9, pos.height])\n",
        "# ax.legend(loc='center right', bbox_to_anchor=(1.33, 0.91), facecolor = 'white')\n",
        "\n",
        "plt.rcParams[\"figure.dpi\"] = 500\n",
        "ax.legend(loc='lower center', bbox_to_anchor=(0.5, -0.5), frameon = True, fontsize = 16)\n",
        "plt.savefig(\"train_accuracies.png\", transparent = True, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUfxcX1D_YOi"
      },
      "outputs": [],
      "source": [
        "x = list(range(len(train_accuracies)))\n",
        "ax = plt.subplot(111)\n",
        "\n",
        "#Feb 5 new: set ticks, axis and spins black\n",
        "ax.spines['left'].set_color('black')        # setting up Y-axis tick color to red\n",
        "ax.spines['bottom'].set_color('black')\n",
        "\n",
        "ax.xaxis.label.set_color('black')        #setting up X-axis label color to yellow\n",
        "ax.yaxis.label.set_color('black')          #setting up Y-axis label color to blue\n",
        "\n",
        "ax.tick_params(axis='x', colors='black')    #setting up X-axis tick color to red\n",
        "ax.tick_params(axis='y', colors='black')  #setting up Y-axis tick color to black\n",
        "\n",
        "plt.plot(x, train_accuracies, 'b', label=\"Train\")\n",
        "plt.plot(x, val_accuracies, 'r', label=\"Validation\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid()\n",
        "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
        "leg.get_frame().set_alpha(0.99)\n",
        "\n",
        "# Add a legend\n",
        "pos = ax.get_position()\n",
        "ax.set_position([pos.x0, pos.y0, pos.width * 0.9, pos.height])\n",
        "ax.legend(loc='center right', bbox_to_anchor=(1.33, 0.91), facecolor = 'white')\n",
        "\n",
        "plt.rcParams[\"figure.dpi\"] = 500\n",
        "\n",
        "plt.rc('font', size=14)\n",
        "# Set the axes title font size\n",
        "plt.rc('axes', titlesize=12)\n",
        "# Set the axes labels font size\n",
        "plt.rc('axes', labelsize=12)\n",
        "# Set the font size for x tick labels\n",
        "plt.rc('xtick', labelsize=16)\n",
        "# Set the font size for y tick labels\n",
        "plt.rc('ytick', labelsize=16)\n",
        "# Set the axes title font size\n",
        "plt.rc('axes', titlesize=12)\n",
        "# Set the axes labels font size\n",
        "plt.rc('axes', labelsize=12)\n",
        "\n",
        "plt.savefig(\"train_accuracies.png\", transparent = True, bbox_inches='tight')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPVs1G+AhOqRKmiEpuCqkc7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}